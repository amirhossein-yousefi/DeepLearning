{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.hw4.part1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnvwqFEinBc5",
        "colab_type": "text"
      },
      "source": [
        "Lets upload data to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAUrJ6xenN00",
        "colab_type": "code",
        "outputId": "ff7f1caf-a1c2-4909-9ed7-3717cef58bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.cm as cm\n",
        "from IPython.core.display import display, HTML\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOke2R29m7mT",
        "colab_type": "code",
        "outputId": "d75e5aac-8e9f-4875-c8cb-2f7a869ae0dc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e4c5b3d1-fb19-464b-b0ba-47cb988be0c4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e4c5b3d1-fb19-464b-b0ba-47cb988be0c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ferdosi.txt to ferdosi.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjjuV4dSgV3S",
        "colab_type": "text"
      },
      "source": [
        "**Data(mesraa) preparation ** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff8ZJHipgPJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################Preparring data#################################################\n",
        "class data_preparation:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        with open(path, encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "            self.max_size  = 0\n",
        "            self.all_chars_set = { '_BOM_','_PAD_', '_EOM_'}\n",
        "            for line in lines:\n",
        "                line = line.rstrip('\\n')\n",
        "                [first_m , second_m] = line.split(',')\n",
        "                first_m = first_m.rstrip(' ').lstrip(' ')\n",
        "                second_m = second_m.rstrip(' ').lstrip(' ')\n",
        "                for c in first_m + second_m:\n",
        "                    self.all_chars_set.add(c)\n",
        "                self.max_size = max(self.max_size, len(first_m))\n",
        "                self.max_size = max(self.max_size, len(second_m))\n",
        "            self.all_chars_dic = {c : idx for idx, c in enumerate(self.all_chars_set)}\n",
        "            self.n_chars = len(self.all_chars_dic)\n",
        "            self.n_examples = len(lines)\n",
        "            self.max_size += 2\n",
        "    def get_data(self):\n",
        "        X = np.zeros((self.n_examples, self.max_size))\n",
        "        Y = np.zeros((self.n_examples, self.max_size))\n",
        "        with open(self.path, encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "            for i, line in enumerate(lines):\n",
        "                line = line.rstrip('\\n')\n",
        "                [first_m , second_m] = line.split(',')\n",
        "                first_m = first_m.rstrip(' ').lstrip(' ')\n",
        "                second_m = second_m.rstrip(' ').lstrip(' ')\n",
        "                X[i, :] = self.line2tensor(first_m, True)\n",
        "                Y[i, :] = self.line2tensor(second_m, False)\n",
        "        return X, Y\n",
        "    def char2idx(self, c):\n",
        "        return self.all_chars_dic[c]\n",
        "\n",
        "    def idx2char(self, idx):\n",
        "        for k, v in self.all_chars_dic.items():\n",
        "            if v == idx:\n",
        "                return k\n",
        "        raise Exception('There is no', idx, ' in all_chars_dic')\n",
        "\n",
        "    def tensor2line(self, tensor, tags=True):\n",
        "        if tags:\n",
        "            return ''.join(self.idx2char(tensor[i]) for i in range(tensor.shape[0]))\n",
        "        else:\n",
        "            return ''.join(self.idx2char(tensor[i]) for i in range(tensor.shape[0])\n",
        "                            if self.idx2char(tensor[i]) not in ['_BOM_', '_EOM_', '_PAD_'])\n",
        "    # add _BOM_ at the begining of line and _EOM_ at the end of line and _PAD_ based on first_flag\n",
        "    def line2tensor(self, line, first_flag):\n",
        "        sz = self.max_size\n",
        "        tensor = np.zeros(sz)\n",
        "        # pad from begining if it's first mesraa\n",
        "        if first_flag:\n",
        "            for i in range(0, sz-len(line)-2):\n",
        "                tensor[i] = self.char2idx('_PAD_')\n",
        "            tensor[sz-len(line)-2]  = self.char2idx('_BOM_')\n",
        "            offset = sz - len(line) - 1\n",
        "            tensor[-1] = self.char2idx('_EOM_')\n",
        "        else:\n",
        "            tensor[0] = self.char2idx('_BOM_')\n",
        "            offset = 1\n",
        "        for i, c in enumerate(line):\n",
        "            tensor[i+offset] = self.char2idx(c)\n",
        "            idx = self.char2idx(c)\n",
        "        # pad at the end if it's second hemistich\n",
        "        if not first_flag:\n",
        "            tensor[len(line)+offset] = self.char2idx('_EOM_')\n",
        "            offset += 1\n",
        "            for i in range(len(line)+offset, sz):\n",
        "                tensor[i] = self.char2idx('_PAD_')\n",
        "        return tensor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh1IeWNbh_tX",
        "colab_type": "text"
      },
      "source": [
        "Model architecture(Sequence2Sequence with and without attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdDhMpq68ILV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########################Model architecture############################\n",
        "class Embedding:\n",
        "  def __init__(self, input_dim, embedding_dim):\n",
        "    with tf.variable_scope(\"Embedding\", reuse=tf.AUTO_REUSE):\n",
        "      self.word_embeddings = tf.get_variable(name='word_embedding', shape=[input_dim, embedding_dim], initializer=tf.random_uniform_initializer(-1, 1))\n",
        "\n",
        "  def __call__(self, input):\n",
        "    with tf.variable_scope(\"Embedding\", reuse=tf.AUTO_REUSE):\n",
        "      embedded = tf.nn.embedding_lookup(self.word_embeddings, input)\n",
        "      return embedded\n",
        "\n",
        "class encoder_RNN:\n",
        "  def __init__(self, input_dim, hidden_dim, n_layers):\n",
        "    with tf.variable_scope(\"encoder_RNN\", reuse=tf.AUTO_REUSE):\n",
        "      self.hidden_dim = hidden_dim\n",
        "      self.input_dim = input_dim\n",
        "      self.n_layers = n_layers\n",
        "\n",
        "      cells = [tf.nn.rnn_cell.LSTMCell(num_units=hidden_dim, use_peepholes=True, state_is_tuple=True) for n in range(n_layers)]\n",
        "      self.lstm = tf.contrib.rnn.MultiRNNCell(cells)\n",
        "\n",
        "  def __call__(self, input, hidden):\n",
        "    with tf.variable_scope(\"encoder_RNN\", reuse=tf.AUTO_REUSE):\n",
        "      output, hidden = tf.nn.dynamic_rnn(self.lstm, input, initial_state=hidden)\n",
        "      return output, hidden\n",
        "\n",
        "  def init_hidden(self, n_batches):\n",
        "    return self.lstm.zero_state(n_batches, dtype=tf.float32)\n",
        "\n",
        "class decoder_RNN:\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
        "    with tf.variable_scope(\"decoder_RNN\", reuse=tf.AUTO_REUSE):\n",
        "      self.input_dim = input_dim\n",
        "      self.hidden_dim = hidden_dim\n",
        "      self.output_dim = output_dim\n",
        "      self.n_layers = n_layers\n",
        "      cells = [tf.nn.rnn_cell.LSTMCell(num_units=hidden_dim, use_peepholes=True, state_is_tuple=True) for n in range(n_layers)]\n",
        "      self.lstm = tf.contrib.rnn.MultiRNNCell(cells)\n",
        "      self.W = tf.get_variable('W', shape=[hidden_dim, output_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
        "      self.b = tf.get_variable('b', shape=[output_dim], initializer=tf.zeros_initializer())\n",
        "  def __call__(self, input, hidden):\n",
        "    with tf.variable_scope(\"decoder_RNN\", reuse=tf.AUTO_REUSE):\n",
        "      output, hidden = self.lstm(input, hidden)\n",
        "      output = tf.tensordot(output, self.W, axes=1) + self.b\n",
        "      return output, hidden\n",
        "class Attn_decoder_RNN:\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
        "    with tf.variable_scope(\"Attention_decoder_RNN\", reuse=tf.AUTO_REUSE):\n",
        "      self.input_dim = input_dim\n",
        "      self.hidden_dim = hidden_dim\n",
        "      self.output_dim = output_dim\n",
        "      self.n_layers = n_layers\n",
        "      cells = [tf.nn.rnn_cell.LSTMCell(num_units=hidden_dim, use_peepholes=True, state_is_tuple=True) for n in range(n_layers)]\n",
        "      self.lstm = tf.contrib.rnn.MultiRNNCell(cells)\n",
        "      self.W = tf.get_variable('W', shape=[hidden_dim, output_dim], initializer=tf.contrib.layers.xavier_initializer())\n",
        "      self.b = tf.get_variable('b', shape=[output_dim], initializer=tf.zeros_initializer())\n",
        "  def __call__(self, input, hidden):\n",
        "    with tf.variable_scope(\"Attention_decoder_RNN\", reuse=tf.AUTO_REUSE):\n",
        "      output, hidden = self.attn_cell(input, hidden)\n",
        "      output = tf.tensordot(output, self.W, axes=1) + self.b\n",
        "      return output, hidden\n",
        "  def init_hidden(self, batch_dim, hidden):\n",
        "    return self.attn_cell.get_initial_state(hidden.h, batch_dim, dtype=tf.float32)\n",
        "  def set_memory(self, memory):\n",
        "    with tf.variable_scope(\"Attention_decoder_RNN\", reuse=tf.AUTO_REUSE):\n",
        "      self.attn = tf.contrib.seq2seq.BahdanauAttention(num_units=self.hidden_dim, memory=memory)\n",
        "      self.attn_cell = tf.contrib.seq2seq.AttentionWrapper(self.lstm, self.attn, alignment_history=True)\n",
        "class Seq2SeqModel:\n",
        "  def __init__(self, encoder, decoder, embedding, max_len, begin_char):\n",
        "    with tf.variable_scope(\"Seq2Seq\", reuse=tf.AUTO_REUSE):\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.embedding = embedding\n",
        "      attention = (type(decoder) == Attn_decoder_RNN)\n",
        "      self.input_data = tf.placeholder(shape=[None, max_len], dtype=tf.int64)\n",
        "      self.target_data = tf.placeholder(shape=[None, max_len], dtype=tf.int64)\n",
        "      self.teacher_forcing = tf.placeholder(tf.float32, [])\n",
        "      self.learning_rate = tf.placeholder(tf.float32, [])\n",
        "      output_dim = self.decoder.output_dim\n",
        "      batch_dim = tf.shape(self.input_data)[0]\n",
        "      enc_embbeded_input = self.embedding(self.input_data)\n",
        "      enc_output, enc_hidden = self.encoder(enc_embbeded_input, self.encoder.init_hidden(batch_dim))\n",
        "      dec_hidden = enc_hidden\n",
        "      dec_input = tf.tile([begin_char], tf.shape(self.input_data)[0:1])\n",
        "      dec_input = tf.dtypes.cast(dec_input, tf.int64)\n",
        "      prediction = [dec_input]\n",
        "      self.loss = 0\n",
        "      if attention:\n",
        "        self.decoder.set_memory(enc_output)\n",
        "        dec_hidden = self.decoder.init_hidden(batch_dim, dec_hidden[-1])\n",
        "      for t in range(1, max_len):\n",
        "        dec_embedded_input = self.embedding(dec_input)\n",
        "        dec_output, dec_hidden = self.decoder(dec_embedded_input, dec_hidden)\n",
        "        self.loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "                      labels=tf.one_hot(self.target_data[:, t], depth=output_dim, dtype=tf.float32),\n",
        "                      logits=dec_output))\n",
        "        next_char = tf.argmax(dec_output, axis=1)\n",
        "        prediction.append(next_char)\n",
        "        teacher_forcing = tf.cond(random.random() < self.teacher_forcing, lambda: True, lambda: False)\n",
        "        dec_input = tf.cond(teacher_forcing, lambda: self.target_data[:, t], lambda: next_char)\n",
        "      if attention:\n",
        "        self.attn_weights = dec_hidden.alignment_history.stack()\n",
        "      self.prediction = tf.transpose(tf.convert_to_tensor(prediction))\n",
        "      self.loss /= max_len\n",
        "      optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
        "      self.opt = optimizer.minimize(self.loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owg9tNx78IR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loader = data_preparation('ferdosi.txt')\n",
        "(X, Y) = loader.get_data()\n",
        "idx = np.random.permutation(X.shape[0])\n",
        "X, Y = X[idx, :], Y[idx, :]\n",
        "test_r = 0.1\n",
        "val_r = 0.1\n",
        "ind1 = int(X.shape[0] * (1-test_r-val_r))\n",
        "ind2 = int(X.shape[0] * (1-test_r))\n",
        "X_train, Y_train = X[:ind1, :], Y[:ind1, :]\n",
        "X_valid, Y_valid = X[ind1:ind2, :], Y[ind1:ind2, :]\n",
        "X_test, Y_test = X[ind2:, :], Y[ind2:, :]\n",
        "data = {'X_train':X_train, 'Y_train':Y_train,\n",
        "        'X_valid':X_valid, 'Y_valid':Y_valid,\n",
        "        'X_test':X_test, 'Y_test':Y_test}\n",
        "params={'batch_size' : 256,'epochs' : 100,'vocabulary_size' : loader.n_chars,'MAX_LEN' : loader.max_size,'EMBEDDING_dim' : 32,'hidden_size' : 256,'the number of layers' : 2,'BEGIN_CHAR' : loader.all_chars_dic['_BOM_'],'learning_rate' : 1e-3,'learning_rate_decay' : 1,'learning_rate_decay_step' : 20,'learning_rate_min': 1e-5,'eps' : 1,'eps_dec' : 0.95,'eps_dec_step' : 30,'eps_thr' : .8}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvV7Rhnd9C0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, data, params, print_every=10):\n",
        "  sess = tf.Session()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  num_of_batches = np.ceil(data['X_train'].shape[0] / params['batch_size'])\n",
        "  \n",
        "  loss_history = []\n",
        "  \n",
        "  for epoch in range(1, params['epochs']+1):\n",
        "      epoch_loss = 0\n",
        "      if epoch % params['learning_rate_decay_step'] == 0: params['learning_rate'] *= params['learning_rate_decay']\n",
        "      if epoch % params['eps_dec_step'] == 0: params['eps'] = max(params['eps_thr'], params['eps'] * params['eps_dec'])\n",
        "        \n",
        "      for i in range(0, data['X_train'].shape[0],  params['batch_size']):\n",
        "        X_b = data['X_train'][i:i+params['batch_size']]\n",
        "        Y_b = data['Y_train'][i:i+params['batch_size']]\n",
        "\n",
        "        _, loss = sess.run([model.opt, model.loss], feed_dict={model.input_data: X_b, \n",
        "                                                               model.target_data: Y_b,\n",
        "                                                               model.learning_rate: params['learning_rate'],\n",
        "                                                               model.teacher_forcing: params['eps']})\n",
        "        epoch_loss += loss / num_of_batches\n",
        "      loss_history.append(epoch_loss)\n",
        "      if epoch % print_every == 0:\n",
        "        print(\"epoch {}, Loss:{}\".format(epoch, epoch_loss))\n",
        "        idx = np.random.randint(0, data['X_valid'].shape[0])\n",
        "        pred = sess.run(model.prediction, feed_dict={model.input_data: data['X_valid'][idx].reshape(1, -1),\n",
        "                                                     model.target_data: data['Y_valid'][idx].reshape(1, -1),\n",
        "                                                     model.teacher_forcing: 0})[0]\n",
        "        print('completed(predicted) poem from validation set:')\n",
        "        print((loader.tensor2line(data['X_valid'][idx], False) + \"  ****  \" + loader.tensor2line(pred, False)))\n",
        "        print(150*'-')\n",
        "  return sess, loss_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMFl7Kke9C3r",
        "colab_type": "code",
        "outputId": "b3b20738-2476-4860-c6ba-d0e67099d3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "embedding = Embedding(params['vocabulary_size'], params['EMBEDDING_dim'])\n",
        "encoder = encoder_RNN(params['vocabulary_size'], params['hidden_size'], params['the number of layers'])\n",
        "decoder = decoder_RNN(params['vocabulary_size'], params['hidden_size'], params['vocabulary_size'], params['the number of layers'])\n",
        "model  = Seq2SeqModel(encoder, decoder, embedding, params['MAX_LEN'], params['BEGIN_CHAR'])\n",
        "model_sess, loss_history = train(model, data, params.copy())\n",
        "test_loss = model_sess.run(model.loss, feed_dict={model.input_data: data['X_test'], model.target_data: data['Y_test'],model.teacher_forcing: 0})\n",
        "print('Test Loss:', test_loss)\n",
        "plt.plot(range(1, params['epochs']+1), loss_history, '-b.',label='epoch loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 10, Loss:0.9912832929537847\n",
            "completed(predicted) poem from validation set:\n",
            "خردمند چون روی گشتاسپ دید  ****  به نزدیک این را بدین افرید\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 20, Loss:0.8276944907429893\n",
            "completed(predicted) poem from validation set:\n",
            "سر تخم ساسانیان بود شاه  ****  که این را نبودی به نزدیک شاه\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 30, Loss:0.9211508917311825\n",
            "completed(predicted) poem from validation set:\n",
            "سپیدی مویش بزیبد همی  ****  زر از درد و بر دشت از اندکی\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 40, Loss:0.7616484087342635\n",
            "completed(predicted) poem from validation set:\n",
            "توی پشت ایران و تاج سران  ****  ز دیتی به کردار دار ان سران\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 50, Loss:0.6853922775182395\n",
            "completed(predicted) poem from validation set:\n",
            "همی چوب زد بر سرش ساروان  ****  بد ان نامور شاه روشن روان\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 60, Loss:0.601227547961454\n",
            "completed(predicted) poem from validation set:\n",
            "همی بود خسرو بران مرغزار  ****  همی کرد باید بدو داستار\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 70, Loss:0.5422152678709096\n",
            "completed(predicted) poem from validation set:\n",
            "تو گفتی ز مستی کنون خاستست  ****  دل و بوم و بر جان نشستتتتتت\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 80, Loss:0.5034313178382431\n",
            "completed(predicted) poem from validation set:\n",
            "ستودان نیابیم یک تن نه گور  ****  برو دار با گنج و با گوپور\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 90, Loss:0.9277109522133682\n",
            "completed(predicted) poem from validation set:\n",
            "نشستند با رای زن بخردان  ****  همان جز بزرگان روشن روان\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 100, Loss:0.5984546886577917\n",
            "completed(predicted) poem from validation set:\n",
            "همی کرد پدرود ان تخت عاج  ****  به در باد بر درد و برکست تاج\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Test Loss: 5.5738397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUikaJYlTRbH",
        "colab_type": "text"
      },
      "source": [
        "Attention model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cjPIYIS9C6v",
        "colab_type": "code",
        "outputId": "f20c3bfe-0383-4acb-b866-da12bf1ba034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "embedding = Embedding(params['vocabulary_size'], params['EMBEDDING_dim'])\n",
        "encoder = encoder_RNN(params['vocabulary_size'], params['hidden_size'], params['the number of layers'])\n",
        "attn_decoder = Attn_decoder_RNN(params['vocabulary_size'], params['hidden_size'], params['vocabulary_size'], params['the number of layers'])\n",
        "attn_model  = Seq2SeqModel(encoder, attn_decoder, embedding, params['MAX_LEN'], params['BEGIN_CHAR'])\n",
        "attn_model_sess, loss_history = train(attn_model, data, params.copy())\n",
        "test_loss = attn_model_sess.run(attn_model.loss, feed_dict={attn_model.input_data: data['X_test'], attn_model.target_data: data['Y_test'],attn_model.teacher_forcing: 0})\n",
        "print('Test Loss:', test_loss)\n",
        "plt.plot(range(1, params['epochs']+1), loss_history, '-b.',label='epoch loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 10, Loss:1.215521026116151\n",
            "completed(predicted) poem from validation set:\n",
            "که پشت همه شهر توران بدوست  ****  بران بر بران بر براند اوری\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 20, Loss:0.996352766186763\n",
            "completed(predicted) poem from validation set:\n",
            "تهمتن چو بشنید گفتار اوی  ****  به بالای او راه بر باد کرد\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 30, Loss:0.9759732563144121\n",
            "completed(predicted) poem from validation set:\n",
            "نه شبرنگ با من نه رهوار بور  ****  به باره بران روز بر بر و روز\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 40, Loss:0.8668158988539987\n",
            "completed(predicted) poem from validation set:\n",
            "دو خونی همان با سپاهی گران  ****  به باره براید ز تن بر گرند\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 50, Loss:0.8104319420571512\n",
            "completed(predicted) poem from validation set:\n",
            "نیا شیر جنگی پدر گیو گرد  ****  به خوبی همی راو بر کوه سرد\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 60, Loss:0.8694488055621964\n",
            "completed(predicted) poem from validation set:\n",
            "برانگیخت کاموس اسپ نبرد  ****  به خوبی برو اندر اورده گرد\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 70, Loss:0.7603707194137267\n",
            "completed(predicted) poem from validation set:\n",
            "توانگر شوی گر تو درویش را  ****  به گفتار بر شهریار من را\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 80, Loss:0.7386398780135776\n",
            "completed(predicted) poem from validation set:\n",
            "ببرد اهرمن گیو را دل ز جای  ****  به پیش سپاه اندر امد ز پای\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 90, Loss:0.6949895201489709\n",
            "completed(predicted) poem from validation set:\n",
            "همان نیز خاتون به کاخ اندورن  ****  که از رنم شیران شوم بر نگن\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "epoch 100, Loss:0.6536529149430302\n",
            "completed(predicted) poem from validation set:\n",
            "ز کین پدر زار و گریان بدم  ****  بران است ازاد برزین دمم\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Test Loss: 5.757934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne08AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwuKyG7rkAq2",
        "colab_type": "text"
      },
      "source": [
        "Predicting second mesraaa by attention and without that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7yyqWA19DAM",
        "colab_type": "code",
        "outputId": "b9024d31-0b89-4afe-dae7-064a0c1ad7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  idx = np.random.randint(0, data['X_test'].shape[0])\n",
        "  pred = model_sess.run(model.prediction, feed_dict={model.input_data: data['X_test'][idx].reshape(1, -1),model.target_data: data['Y_test'][idx].reshape(1, -1),model.teacher_forcing: 0})\n",
        "  attn_pred, weights = attn_model_sess.run([attn_model.prediction, attn_model.attn_weights], feed_dict={attn_model.input_data: data['X_test'][idx].reshape(1, -1),attn_model.target_data: data['Y_test'][idx].reshape(1, -1),attn_model.teacher_forcing: 0})\n",
        "  first_m = loader.tensor2line(data['X_test'][idx], False)\n",
        "  second_m_true = loader.tensor2line(data['Y_test'][idx], False)\n",
        "  second_m_1 = loader.tensor2line(pred[0], False)\n",
        "  second_m_2 = loader.tensor2line(attn_pred[0], False)\n",
        "  print('Test input:',i)\n",
        "  print(first_m + \"  ****  \" + second_m_true)\n",
        "  print('Seq2Seq output:')\n",
        "  print(second_m_1)\n",
        "  print('Seq2Seq with attention output:')\n",
        "  print(second_m_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test input: 0\n",
            "چنین داد پاسخ که گر شهریار  ****  براندیشد از کار اسفندیار\n",
            "Seq2Seq output:\n",
            "به این نامداران رومی مدار\n",
            "Seq2Seq with attention output:\n",
            "بران نامور بخرگاه اندرار\n",
            "Test input: 1\n",
            "ز فرهاد و گیوت برارم بجاه  ****  بگنج و سپاه و بتخت و کلاه\n",
            "Seq2Seq output:\n",
            "بران را به ایران نیاین به راه\n",
            "Seq2Seq with attention output:\n",
            "برفتند با او به ایوان شاه\n",
            "Test input: 2\n",
            "همان تیغ هندی و رومی هزار  ****  بفرمود با جوشن کارزار\n",
            "Seq2Seq output:\n",
            "سرامد برو رنجه شیرخور\n",
            "Seq2Seq with attention output:\n",
            "بران نامور تخت شاهی نگار\n",
            "Test input: 3\n",
            "به خسرو چنین گفت کای سرفراز  ****  نگه کن بدان بنده دیوساز\n",
            "Seq2Seq output:\n",
            "به چنگ اندرون گرز و گردش نیاز\n",
            "Seq2Seq with attention output:\n",
            "بران بر نشینم مرا رهنماز\n",
            "Test input: 4\n",
            "چو هم پشت باشید با همرهان  ****  یکی کوه کندن ز بن بر توان\n",
            "Seq2Seq output:\n",
            "بب شید و بر ماه پیر مهان\n",
            "Seq2Seq with attention output:\n",
            "بران شار بر تخت بر شاهان\n",
            "Test input: 5\n",
            "چو دو ابگیرش پر از خون دو چشم  ****  مرا دید غرید و امد به خشم\n",
            "Seq2Seq output:\n",
            "بکی اتش از بر یکی گرد نشم\n",
            "Seq2Seq with attention output:\n",
            "برو پشت پیلان مگیرادگش\n",
            "Test input: 6\n",
            "ولیکن به گیتی بجز تاج و تخت  ****  چه جوید خردمند بیدار بخت\n",
            "Seq2Seq output:\n",
            "برو با ترا نیز بر زر به بخت\n",
            "Seq2Seq with attention output:\n",
            "بران گو از اور به بی رنج بخت\n",
            "Test input: 7\n",
            "زبان راندن و دیده بی اب شرم  ****  گزیدن خروش اندر اواز نرم\n",
            "Seq2Seq output:\n",
            "که گردون برارد مرا پیش گرم\n",
            "Seq2Seq with attention output:\n",
            "برانگیزم از را دو اندیشه گم\n",
            "Test input: 8\n",
            "بدو هفته از رومیان سی هزار  ****  گرفتند و امد بر شهریار\n",
            "Seq2Seq output:\n",
            "گری از تن خویشتن بی گران\n",
            "Seq2Seq with attention output:\n",
            "برانگیزگرفتند بر گوش و زار\n",
            "Test input: 9\n",
            "ز گفتار او شاد شد شاه هند  ****  بیاراست ایوان به چینی پرند\n",
            "Seq2Seq output:\n",
            "بدان تا نباشد به دشت نژرد\n",
            "Seq2Seq with attention output:\n",
            "بران نامور بارگاه امدند\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtPtNUn19DDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}