{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r89rYJP6C1wZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "#part a,b,c,d,e\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# np.random.seed(42)\n",
    "mu=10\n",
    "sigma=1\n",
    "a=np.random.normal(loc=mu,scale=sigma,size=10000)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(4,1,1)\n",
    "plt.title('Gaussian ddistribution')\n",
    "_, bins, _ = plt.hist(a, 100, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * \\\n",
    "              np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='r')\n",
    "b=np.random.choice(a,200)\n",
    "#print(np.mean(b))#\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(4,1,2)\n",
    "plt.title('random sampling method1(choice)')\n",
    "_, bins, _ = plt.hist(b, 100, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * \\\n",
    "              np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='r')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(4,1,3)\n",
    "plt.title('random sampling method2(sample)')\n",
    "c=random.sample(list(a),200)\n",
    "_, bins, _ = plt.hist(c, 100, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * \\\n",
    "              np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='r')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(4,1,4)\n",
    "plt.title('Unoform distribution')\n",
    "uni=np.random.uniform(low=-1,high=1,size=10000)\n",
    "_,bins,_=plt.hist(uni,density=True)\n",
    "plt.plot(bins,bins/bins*.5,color='r')\n",
    "\n",
    "\n",
    "\n",
    "#part f\n",
    "alpha=uni*a\n",
    "print(alpha)\n",
    "sigma=5\n",
    "mu=0\n",
    "_, bins, _ = plt.hist(alpha, 100, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * \\\n",
    "              np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='r')\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) * \\\n",
    "              np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "          linewidth=2, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0Z4b5txC-M6",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "#section b\n",
    "pd=pd.read_csv('/Users/amirhossein/Desktop/sharif/third semester/Deep Learning/DL2019-HW01/img.csv')\n",
    "pd=pd.to_numpy()\n",
    "plt.matshow(pd)\n",
    "plt.show()\n",
    "\n",
    "#section d\n",
    "import cv2\n",
    "a=cv2.imread('/Users/amirhossein/Desktop/sharif/third semester/Deep Learning/DL2019-HW01/img.jpg')\n",
    "cv2.imshow('image',a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#section f\n",
    "from tempfile import TemporaryFile\n",
    "!--upgrade pip Image\n",
    "import Image\n",
    "# outfile = TemporaryFile()\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "dst = cv2.filter2D(a,-1,kernel)\n",
    "im = Image.fromarray(dst)\n",
    "im.save('output.jpg')\n",
    "# np.save(outfile,dst)\n",
    "cv2.imshow('image',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0zWVo-bDCPF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# #part b\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()\n",
    "plt.gray()\n",
    "for i in range(10):\n",
    "    plt.matshow(digits.images[i]) \n",
    "    plt.show() \n",
    "\n",
    "\n",
    "#part c\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn import svm\n",
    "x_train,x_test,y_train,y_test=train_test_split(digits.data,digits.target,test_size=.25,shuffle=True,random_state=12)\n",
    "degree=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "accuracy=[]\n",
    "for i in degree:\n",
    "    svmClassifier=svm.SVC(gamma=.01,kernel='poly',degree=i)\n",
    "    svmClassifier.fit(x_train,y_train)    \n",
    "    y_pred=svmClassifier.predict(x_test)\n",
    "    accuracy.append(accuracy_score(y_pred,y_test))\n",
    "fig= plt.figure(figsize=(30,10))\n",
    "plt.axis([0,20,0.8,1])\n",
    "plt.xlabel('polynomial degree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(degree,accuracy,color='r',linewidth=5)\n",
    "plt.show()\n",
    "print('maximum accuracy is',np.max(accuracy))\n",
    "print(accuracy)\n",
    "\n",
    "#part d\n",
    "svmClassifier=svm.SVC(gamma=.01,kernel='poly',degree=3)\n",
    "svmClassifier.fit(x_train,y_train)    \n",
    "y_pred=svmClassifier.predict(x_test)\n",
    "accuracy.append(accuracy_score(y_pred,y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#part d for more clarification\n",
    "class_names = digits.target_names\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DeepLearning HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
